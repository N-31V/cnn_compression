{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-03T17:14:19.609175902Z",
     "start_time": "2023-07-03T17:14:18.874792287Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/n31v/workspace/Fedot.Industrial')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from fedot_ind.core.architecture.datasets.splitters import get_dataset_mean_std, split_data, undersampling, dataset_info\n",
    "\n",
    "DATASETS_ROOT = '/media/n31v/data/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageNet\n",
    "mean=(0.13066,), std=(0.3081,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "\n",
    "imagenet_ds = ImageNet('/media/n31v/data/datasets/imagenet-object-localization-challenge')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST\n",
    "mean=(0.1306,), std=(0.308,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing mean and std: 100%|██████████| 60000/60000 [00:05<00:00, 11771.05it/s]\n",
      "prepare dataset: 100%|██████████| 60000/60000 [00:03<00:00, 19225.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5923 samples.\n",
      "Class 1 contains 6742 samples.\n",
      "Class 2 contains 5958 samples.\n",
      "Class 3 contains 6131 samples.\n",
      "Class 4 contains 5842 samples.\n",
      "Class 5 contains 5421 samples.\n",
      "Class 6 contains 5918 samples.\n",
      "Class 7 contains 6265 samples.\n",
      "Class 8 contains 5851 samples.\n",
      "Class 9 contains 5949 samples.\n",
      "mean=(0.13066047797803165,), std=(0.3081078048756658,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(mnist_ds)\n",
    "dataset_info(mnist_ds, verbose=True)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T14:31:27.243364565Z",
     "start_time": "2023-07-03T14:31:18.947471557Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_ds = undersampling(mnist_ds, n=5000, verbose=True)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(mnist_ds, 2, verbose=True)\n",
    "    folds.append(np.array([mnist_ds.indices[f1], mnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'MNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'MNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1, verbose=True)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST\n",
    "mean=(0.286,), std=(0.353,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing mean and std: 100%|██████████| 60000/60000 [00:05<00:00, 11832.54it/s]\n",
      "prepare dataset: 100%|██████████| 60000/60000 [00:03<00:00, 19689.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 6000 samples.\n",
      "Class 1 contains 6000 samples.\n",
      "Class 2 contains 6000 samples.\n",
      "Class 3 contains 6000 samples.\n",
      "Class 4 contains 6000 samples.\n",
      "Class 5 contains 6000 samples.\n",
      "Class 6 contains 6000 samples.\n",
      "Class 7 contains 6000 samples.\n",
      "Class 8 contains 6000 samples.\n",
      "Class 9 contains 6000 samples.\n",
      "mean=(0.28604060299881057,), std=(0.35302425013288347,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fmnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(fmnist_ds)\n",
    "dataset_info(fmnist_ds, verbose=True)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T14:32:41.616535485Z",
     "start_time": "2023-07-03T14:32:33.418594516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prepare dataset: 100%|██████████| 60000/60000 [00:03<00:00, 19428.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of any class 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prepare dataset: 100%|██████████| 50000/50000 [00:02<00:00, 18737.33it/s]\n",
      "prepare dataset: 100%|██████████| 50000/50000 [00:02<00:00, 18764.20it/s]\n",
      "prepare dataset: 100%|██████████| 50000/50000 [00:02<00:00, 19031.05it/s]\n",
      "prepare dataset: 100%|██████████| 50000/50000 [00:02<00:00, 18623.86it/s]\n",
      "prepare dataset: 100%|██████████| 50000/50000 [00:02<00:00, 18913.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 25000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fmnist_ds = undersampling(fmnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(fmnist_ds, 2)\n",
    "    folds.append(np.array([fmnist_ds.indices[f1], fmnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T14:33:07.830985002Z",
     "start_time": "2023-07-03T14:32:51.386958365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1, verbose=True)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10\n",
    "mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.262)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing mean and std: 100%|██████████| 50000/50000 [00:04<00:00, 10643.16it/s]\n",
      "prepare dataset: 100%|██████████| 50000/50000 [00:03<00:00, 16440.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5000 samples.\n",
      "Class 1 contains 5000 samples.\n",
      "Class 2 contains 5000 samples.\n",
      "Class 3 contains 5000 samples.\n",
      "Class 4 contains 5000 samples.\n",
      "Class 5 contains 5000 samples.\n",
      "Class 6 contains 5000 samples.\n",
      "Class 7 contains 5000 samples.\n",
      "Class 8 contains 5000 samples.\n",
      "Class 9 contains 5000 samples.\n",
      "mean=(0.4913996927399561, 0.4821584222899936, 0.4465309280202538), std=(0.24703223297351337, 0.2434851287896555, 0.26158784042441807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(cifar10_ds)\n",
    "dataset_info(cifar10_ds, verbose=True)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T14:41:47.447221069Z",
     "start_time": "2023-07-03T14:41:39.321691565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = []\n",
    "for i in range(5):\n",
    "    folds.append(np.array(split_data(cifar10_ds, 2, verbose=True)))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds.npy'))\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=cifar10_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1, verbose=True)\n",
    "    fold2 = Subset(dataset=cifar10_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageFolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def check_dataset(dataset: str):\n",
    "    folds = np.load(os.path.join(DATASETS_ROOT, dataset, 'folds.npy'))\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        fold1 = Subset(dataset=ds, indices=folds[i, 0, :])\n",
    "        dataset_info(fold1, verbose=True)\n",
    "        fold2 = Subset(dataset=ds, indices=folds[i, 1, :])\n",
    "        dataset_info(fold2, verbose=True)\n",
    "\n",
    "def prepare_dataset(dataset: str, udersampling: bool = True, check: bool = True, n: Optional[int] = None):\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    classes = dataset_info(ds, verbose=True)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('dataset info:')\n",
    "    print('------------------------------------------------------------------')\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    for k, v in classes.items():\n",
    "        print(f\"Class {k} {idx_to_class[k]} contains {v} samples.\")\n",
    "    print(f'{mean=}, {std=}')\n",
    "    if udersampling:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('undersamling...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        if n is None:\n",
    "            n = min(classes.values())\n",
    "            n = n if n % 2 == 0 else n - 1\n",
    "        ds = undersampling(ds, n=n)\n",
    "        mean, std = get_dataset_mean_std(ds)\n",
    "        print(f'{mean=}, {std=}')\n",
    "        folds = []\n",
    "        for i in range(5):\n",
    "            f1, f2 = split_data(ds, 2)\n",
    "            folds.append(np.array([ds.indices[f1], ds.indices[f2]]))\n",
    "        folds = np.array(folds)\n",
    "        np.save(os.path.join(DATASETS_ROOT, dataset, 'folds'), folds)\n",
    "        print(folds.shape)\n",
    "    if check:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('checking dataset...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        check_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T17:14:19.615458214Z",
     "start_time": "2023-07-03T17:14:19.613863753Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land-Use_Scene_Classification\n",
    "mean=(0.459, 0.468, 0.437), std=(0.288, 0.280, 0.269)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'Land-Use_Scene_Classification/images'), n=500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals 200x200\n",
    "mean=(0.54, 0.61, 0.51), std=(0.22, 0.23, 0.23)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'minerals_21'), n=500)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
